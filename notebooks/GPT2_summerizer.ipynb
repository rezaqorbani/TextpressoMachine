{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import GPT2LMHeadModel\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "from tqdm import tnrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "import bert_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XSumPreprocessor:\n",
    "    def __init__(self, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Add special tokens to the tokenizer\n",
    "        self.special_tokens_dict = {'bos_token': '<bos>', 'eos_token': '<eos>', 'sep_token': '<sep>', 'pad_token': '<pad>'}\n",
    "        self.num_added_toks = self.tokenizer.add_special_tokens(self.special_tokens_dict)\n",
    "    def preprocess(self, example):\n",
    "        # Concatenate article and summary and add special tokens\n",
    "        encoded_example = tokenizer.encode_plus(\n",
    "            f'{self.special_tokens_dict[\"bos_token\"]} {example[\"document\"]} {self.special_tokens_dict[\"sep_token\"]} {example[\"summary\"]} {self.special_tokens_dict[\"eos_token\"]}',\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "\n",
    "        return encoded_example\n",
    "\n",
    "    def filter(self, dataset):\n",
    "        dataset = [sample for sample in dataset if self.tokenizer.sep_token_id in sample['input_ids']]\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xsum (/home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b036a38886f437da76fe73c35ed5116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xsum (/home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n",
      "Found cached dataset xsum (/home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n",
      "Found cached dataset xsum (/home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n",
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-f7cfd4753b2ff669.arrow\n",
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-fed812113622a2f8.arrow\n",
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-07fddc0ce59e52fa.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "max_length=1024\n",
    "\n",
    "preprocessor = XSumPreprocessor(\n",
    "                tokenizer = tokenizer,\n",
    "                max_length = max_length\n",
    ")\n",
    "\n",
    "# Load XSum dataset\n",
    "xsum_dataset = load_dataset('xsum')\n",
    "\n",
    "use_percent = 100\n",
    "# dataset_train = load_dataset(\"xsum\", split=f\"train[:{use_percent}%]\")\n",
    "# dataset_val = load_dataset(\"xsum\", split=f\"validation[:{use_percent*2}%]\")\n",
    "# dataset_test = load_dataset(\"xsum\", split=f\"test[:{use_percent}%]\")\n",
    "dataset_train = load_dataset(\"xsum\", split=f\"train[:{use_percent}]\")\n",
    "dataset_val = load_dataset(\"xsum\", split=f\"validation[:{use_percent}]\")\n",
    "dataset_test = load_dataset(\"xsum\", split=f\"test[:{use_percent}]\")\n",
    "\n",
    "dataset = DatasetDict({'train': dataset_train, 'validation': dataset_val, 'test': dataset_test})\n",
    "\n",
    "# Apply the function to all examples in the dataset\n",
    "xsum_dataset = dataset.map(preprocessor.preprocess, remove_columns=['document', 'summary'])\n",
    "# Format the dataset to PyTorch tensors and split into training, validation, and test sets\n",
    "xsum_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "train_dataset = preprocessor.filter(xsum_dataset['train'])\n",
    "val_dataset = preprocessor.filter(xsum_dataset['validation'])\n",
    "test_dataset = xsum_dataset['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### TODO: Save losses while training ###\n",
    "### TODO: Add Checkpointing ###\n",
    "\n",
    "\n",
    "class GPT2FineTuner(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "        # Resize token embeddings in case you have added more tokens in the vocab\n",
    "        self.model.resize_token_embeddings(len(tokenizer))\n",
    "        self.train_losses = []\n",
    "        self.validation_losses = []\n",
    "        \n",
    "        self.train_losses_epoch=[]\n",
    "        self.validation_losses_epoch=[]\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        return self.model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        input_ids, attention_mask = batch['input_ids'], batch['attention_mask']\n",
    "        sep_positions = (input_ids == tokenizer.sep_token_id).nonzero(as_tuple=False)\n",
    "        # Forward pass\n",
    "        outputs = self(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Calculate loss only on the reference summary\n",
    "        loss = 0\n",
    "        for i, sep_position in enumerate(sep_positions):\n",
    "            sep_position = sep_position[1]  # Use the single element from the tensor\n",
    "            shift_logits = logits[i, sep_position:-1,:].contiguous()\n",
    "            shift_labels = input_ids[i, sep_position+1:].contiguous()\n",
    "            loss_calculation = cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            loss += loss_calculation if not torch.isnan(loss_calculation) else 0\n",
    "\n",
    "        loss = loss / len(sep_positions)  # average loss\n",
    "        self.train_losses.append(loss)\n",
    "        self.log('loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        input_ids, attention_mask = batch['input_ids'], batch['attention_mask']\n",
    "        sep_positions = (input_ids == tokenizer.sep_token_id).nonzero(as_tuple=False)\n",
    "        # Forward pass\n",
    "        outputs = self(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "       # Calculate loss only on the reference summary\n",
    "        val_loss = 0\n",
    "        for i, sep_position in enumerate(sep_positions):\n",
    "            sep_position = sep_position[1] # Use the single element from the tensor\n",
    "            shift_logits = logits[i, sep_position:-1, :].contiguous()\n",
    "            shift_labels = input_ids[i, sep_position+1:].contiguous()\n",
    "            val_loss += cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "        val_loss = val_loss / len(sep_positions)  # average loss\n",
    "        self.validation_losses.append(val_loss)\n",
    "        self.log('val_loss', val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return {'val_loss': val_loss}\n",
    "    \n",
    "    def generate(self, input_ids, max_new_tokens=30, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "        input_ids=input_ids.clone().detach().reshape((1,-1)).to(device)\n",
    "        return self.model.generate(input_ids)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Calculate average loss for the epoch and append to the list\n",
    "        avg_train_loss = sum(self.train_losses)/ len(self.train_losses)\n",
    "        self.train_losses_epoch.append(avg_train_loss.item())\n",
    "\n",
    "        # Reset epoch loss accumulator\n",
    "        self.train_losses = []\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Calculate average loss for the epoch and append to the list\n",
    "        avg_val_loss = sum(self.validation_losses) / len(self.validation_losses)\n",
    "        self.validation_losses_epoch.append(avg_val_loss.item())\n",
    "\n",
    "        # Reset epoch loss accumulator\n",
    "        self.validation_losses = []\n",
    "\n",
    "    def push_to_hub(self, model_name, organization):\n",
    "        # Save the model\n",
    "        self.model.push_to_hub(model_name, organization)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, batch_size=2, num_workers=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /home/studio-lab-user/dev/TextpressoMachine/notebooks/saved/saved_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 124 M \n",
      "------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "497.772   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb386b8cfb314f6da6feb18b257b09fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2FineTuner()\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # Choose your metric here\n",
    "    dirpath='./saved/saved_checkpoints/',\n",
    "    filename='GPT2FineTuner-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='min',  # or 'max', depending on what you want to monitor\n",
    ")\n",
    "\n",
    "trainer = Trainer(max_epochs=3, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model)\n",
    "\n",
    "### NB: Will workd once losses are saved ###\n",
    "#print('training loss', model.train_losses)\n",
    "#print('validation loss', model.validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the losses\n",
    "train_losses= model.train_losses_epoch\n",
    "validation_losses= model.validation_losses_epoch\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(validation_losses[1:], label='Validation Loss')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('T5: Losses over Epochs')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('losses_plot.png')\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch0: val_loss 0.167\n",
    "epoch1: val_loss 0.163\n",
    "epoch2: val_loss 0.165\n",
    "epoch3: val_loss 0.174\n",
    "epoch4: val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"./saved/tokenizers/\")\n",
    "\n",
    "# The best model is saved at the path:\n",
    "checkpoint_path = checkpoint_callback.best_model_path\n",
    "model = GPT2FineTuner.load_from_checkpoint(checkpoint_path)\n",
    "model.eval()\n",
    "gpt2_summarizer = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(model, text, length, device):\n",
    "    ## From the blog ##\n",
    "    text = torch.tensor(text, dtype=torch.long, device=device)\n",
    "    text = text.unsqueeze(0)\n",
    "    generated = text\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in tnrange(length):\n",
    "            inputs = {'input_ids': generated}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            next_token_logits = outputs[0][0, -1, :]\n",
    "            next_token = torch.multinomial(F.softmax(next_token_logits, dim=-1), num_samples=1)\n",
    "            generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
    "    return generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./saved/tokenizers/\")\n",
    "example = test_dataset[0]['input_ids']\n",
    "sep_idx = (example == tokenizer.sep_token_id).nonzero(as_tuple=False).item()\n",
    "print(sep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3582/1770653979.py:8: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for _ in tnrange(length):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f93f133a3d494aaabae76008635bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "text = example[:sep_idx].tolist()\n",
    "summary = example[sep_idx+1:].tolist()\n",
    "generated_text = summarize(gpt2_summarizer, text, length=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tokenized_summary = generated_text[0, sep_idx:].tolist()\n",
    "# tokenized_summary = generated_text[0,:].tolist()\n",
    "id_summary = tokenizer.convert_ids_to_tokens(tokenized_summary,skip_special_tokens=True)\n",
    "print(len(id_summary))\n",
    "gpt2_summary = tokenizer.convert_tokens_to_string(id_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Original Text #############\n",
      "<bos> Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\n",
      "Workers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\n",
      "The Welsh Government said more people than ever were getting help to address housing problems.\n",
      "Changes to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\n",
      "Prison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\n",
      "However, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\n",
      "Andrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was \"chronic\".\n",
      "\"There's a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,\" he said.\n",
      "\"It could take six months to a year, without a lot of help they could be on the streets for six months.\n",
      "\"When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.\"\n",
      "Mr Stevens believes building more one-bedroom flats could help ease the problem.\n",
      "\"The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,\" he said.\n",
      "Official figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\n",
      "Marc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\n",
      "He said he would ask himself: \"Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.\"\n",
      "\"You're put out among the same sort of people doing the same sort of thing, and it's difficult, it's difficult to get away from it. It's like every man for himself, there's nothing.\"\n",
      "Marc has now found stable accommodation with homeless charity Emmaus and said it had been life changing.\n",
      "\"You feel safe, you got hot food, you've got company of people in similar situations to yourself but all dealing with different issues. It's a constructive, helpful atmosphere,\" he said.\n",
      "Tom Clarke, chief executive of Emmaus South Wales, agreed there was not enough support available.\n",
      "\"We do still see [people] homeless on the streets, so clearly they haven't got accommodation and haven't got provision,\" he said.\n",
      "\"I think the key is connecting people with the services they need. I don't delude myself that Emmaus can offer a one size fits all for everyone, we can't.\n",
      "\"But there must be other opportunities and given suitable encouragement I believe that can and should happen.\"\n",
      "A Welsh Government spokesman said the national pathway for homeless services to children, young people and adults in the secure estate had prevented many people from losing their home whilst serving their prison sentence.\n",
      "It added there were already significant demands for one-bedroom flats across the public and private sector and it was providing 20,000 new affordable homes in the next five years.\n",
      "\n",
      "######### GPT2 Summary ##############\n",
      "\n",
      "\n",
      "######### Ground Truth Summary ###########\n",
      "There is a \"chronic\" need for more housing for prison leavers in Wales, according to a charity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('######### Original Text #############')\n",
    "print(tokenizer.decode(text), end='\\n\\n')\n",
    "print('######### GPT2 Summary ##############')\n",
    "print(gpt2_summary, end='\\n\\n')\n",
    "print('######### Ground Truth Summary ###########')\n",
    "print(tokenizer.decode(summary, skip_special_tokens=True), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, hypothesis, reference):\n",
    "        self.hypothesis = hypothesis\n",
    "        self.reference = reference\n",
    "        \n",
    "        self.metrics={\n",
    "        'rouge1': self.rouge_N(1),\n",
    "        'rouge2': self.rouge_N(2),\n",
    "        'rougeL': self.rouge_L(),\n",
    "        'rougeLsum': self.rouge_L_sum(),\n",
    "        'bert': self.bert_Score()\n",
    "    }\n",
    "        \n",
    "    def rouge_L(self):\n",
    "        metric = load(\"rouge\")\n",
    "        metric_type = 'rougeL'\n",
    "        rg_score = metric.compute(predictions=self.hypothesis, references=self.reference, rouge_types=[metric_type])[metric_type]\n",
    "        print('rougeL computed')\n",
    "        return rg_score\n",
    "        \n",
    "    \n",
    "    def rouge_N(self, n=1):\n",
    "        metric = load(\"rouge\")\n",
    "        metric_type = f'rouge{n}'\n",
    "        rg_score = metric.compute(predictions=self.hypothesis, references=self.reference, rouge_types=[metric_type])[metric_type]\n",
    "        print('rougeN computed')\n",
    "        return rg_score\n",
    "\t\t\n",
    "\t\t\n",
    "    def rouge_L_sum(self):\n",
    "        metric = load(\"rouge\")\n",
    "        metric_type = 'rougeLsum'\n",
    "        rg_score = metric.compute(predictions=self.hypothesis, references=self.reference, rouge_types=[metric_type])[metric_type]\n",
    "        print('rougeLsum computed')\n",
    "        return rg_score\n",
    "\t\t\n",
    "        \n",
    "    def bert_Score(self):\n",
    "        metric = load(\"bertscore\")\n",
    "        all_preds= bert_score.score(self.hypothesis, self.reference, lang='en')\n",
    "        score = {\"precision\": (torch.sum(all_preds[0].cpu())/all_preds[0].cpu().numel()).item(), \"recall\": (torch.sum(all_preds[1].cpu())/all_preds[1].cpu().numel()).item(), \"f1\":\n",
    "                (torch.sum(all_preds[2].cpu())/all_preds[2].cpu().numel()).item()}\n",
    "        print('Bert computed')\n",
    "        return score\n",
    "    \n",
    "    def rouge_L_evaluation(self):\n",
    "        # Tokenize hypothesos and reference sentences\n",
    "        hypothesis_tokens = self.hypothesis.split()\n",
    "        reference_tokens = self.reference.split()\n",
    "\n",
    "        # Compute the length of the longest common subsequence\n",
    "        lcs = lcs_length(hypothesis_tokens, reference_tokens)\n",
    "\n",
    "        # Compute precision, recall, and f1 score\n",
    "        precision = lcs / len(hypothesis_tokens)\n",
    "        recall = lcs / len(reference_tokens)\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall + 1e-7))\n",
    "\n",
    "        return {\"precision\": precision, \"recall\": recall, \"f1\": f1_score}\n",
    "\n",
    "\n",
    "    def rouge_N_evaluation(self, n=1):\n",
    "        # split sentences into n-grams\n",
    "        def ngrams(sentence, n):\n",
    "            # use a list comprehension to generate n-grams\n",
    "            return Counter([tuple(sentence[i:i+n]) for i in range(len(sentence) - n + 1)])\n",
    "\n",
    "        # compute the n-grams for the candidate and reference sentences\n",
    "        hypothesis_ngrams = ngrams(self.hypothesis.split(\" \"), n)\n",
    "        reference_ngrams = ngrams(self.reference.split(\" \"), n)\n",
    "\n",
    "        # count the number of shared n-grams\n",
    "        shared_ngrams = hypothesis_ngrams & reference_ngrams\n",
    "        shared_count = sum(shared_ngrams.values())\n",
    "\n",
    "        # calculate precision, recall, and f1 score\n",
    "        precision = shared_count / sum(hypothesis_ngrams.values())\n",
    "        recall = shared_count / sum(reference_ngrams.values())\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall + 1e-7))\n",
    "\n",
    "        return {\"precision\": precision, \"recall\": recall, \"f1\": f1_score}\n",
    "    \n",
    "    def rouge_L_sum_evaluation(self):\n",
    "        # Tokenize candidate and reference summaries\n",
    "        hypothesis_tokens = self.hypothesis.split()\n",
    "        reference_tokens = self.reference.split()\n",
    "\n",
    "        # Compute the length of the longest common subsequence for summarizations\n",
    "        lcs_sum = lcs_length(hypothesis_tokens, reference_tokens)\n",
    "\n",
    "        # Compute precision, recall, and f1 score\n",
    "        precision = lcs_sum / len(hypothesis_tokens)\n",
    "        recall = lcs_sum / len(reference_tokens)\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall + 1e-7))\n",
    "\n",
    "        return {\"precision\": precision, \"recall\": recall, \"f1\": f1_score}\n",
    "    \n",
    "    @staticmethod\n",
    "    def lcs_length(s1, s2):\n",
    "            m, n = len(s1), len(s2)\n",
    "            dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "            for i in range(1, m + 1):\n",
    "                for j in range(1, n + 1):\n",
    "                    if s1[i - 1] == s2[j - 1]:\n",
    "                        dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                    else:\n",
    "                        dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "            return dp[m][n]\n",
    "        \n",
    "        \n",
    "def evaluate_model(test_data, model, tokenizer, device):\n",
    "        reference=[]\n",
    "        candidate=[]\n",
    "        for input_text_ids, summary in zip(test_data['input_ids'], test_data['summary']):\n",
    "            \n",
    "            input_text_ids=torch.tensor(input_text_ids).clone().detach().reshape((1,-1)).to(device)\n",
    "            generated_summary = model.generate(input_text_ids)  # Generate summary using your model's generate function\n",
    "            gen_summary=tokenizer.decode(generated_summary[0], skip_special_tokens=True)\n",
    "            reference.append(summary)\n",
    "            candidate.append(gen_summary)\n",
    "        scores = Evaluator(candidate, reference).metrics\n",
    "        \n",
    "        return scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/studio-lab-user/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71/cache-18c21e355d9702c0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['document', 'summary', 'id', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 1024, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rougeN computed\n",
      "rougeN computed\n",
      "rougeL computed\n",
      "rougeLsum computed\n"
     ]
    }
   ],
   "source": [
    "xsum_dataset = dataset.map(preprocessor.preprocess)\n",
    "# xsum_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "test_dataset = xsum_dataset[\"train\"]\n",
    "print(test_dataset)\n",
    "scores=evaluate_model(test_dataset, model, tokenizer, device)\n",
    "bert_scores=scores['bert']\n",
    "rouge_1_score=scores['rouge1']\n",
    "rouge_2_score=scores['rouge2']\n",
    "rouge_L_score=scores['rougeL']\n",
    "rouge_L_sum_score=scores['rougeLsum']\n",
    "print('Bert Scores: Precision ',bert_scores['precision'],'| Recall ',bert_scores['recall'],'| F1Score ',bert_scores['f1'])\n",
    "print('Rouge-1 Score: ',rouge_1_score)\n",
    "print('Rouge-2 Score: ',rouge_2_score)\n",
    "print('Rouge-L Score: ',rouge_L_score)\n",
    "print('Rouge-L-summ Score: ',rouge_L_sum_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
